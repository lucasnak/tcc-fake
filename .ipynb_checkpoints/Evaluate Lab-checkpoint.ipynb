{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from IPython.display import display # for displaying pandas style - display(df.head())\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.metrics import classification_report , confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definePath(name):\n",
    "    '''Simple function that gets the user's name and returns its database path. '''\n",
    "    if name == 'vitor':\n",
    "        path = r'C:\\Users\\vitor\\Documents\\TCC.v3\\Fake.br-Corpus\\full_texts'\n",
    "    elif name == 'lucas':\n",
    "        path = r'C:\\Users\\nakam\\Documents\\Python Scripts\\Fake\\Fake.br-Corpus\\full_texts'\n",
    "    else:\n",
    "        print('Não reconhecido. Vitor, é você né?')\n",
    "    return path\n",
    "\n",
    "def txtToDataframe(path):\n",
    "    '''Function for converting full texts to a single DataFrame.'''\n",
    "    true_files = [path+\"\\\\true\\\\\"+f for f in os.listdir(path+'\\\\true') if isfile(join(path+'\\\\true', f))]\n",
    "    fake_files = [path+\"\\\\fake\\\\\"+f for f in os.listdir(path+'\\\\fake') if isfile(join(path+'\\\\fake', f))]\n",
    "    \n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in true_files:\n",
    "        with open(file, encoding='utf8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append('true')\n",
    "    for file in fake_files:\n",
    "        with open(file, encoding='utf8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append('fake')\n",
    "    df = pd.DataFrame(list(zip(texts,labels)),columns=['texts','labels'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def definePathEvaluate(name):\n",
    "    '''Simple function that gets the user's name and returns its database from Extract path. '''\n",
    "    if name == 'vitor':\n",
    "        path = r'C:\\Users\\vitor\\Documents\\TCC.v3\\Software'\n",
    "    elif name == 'lucas':\n",
    "        path = r'C:\\Users\\nakam\\Documents\\Python Scripts\\Fake\\Software'\n",
    "    else:\n",
    "        print('Não reconhecido. Vitor, é você né?')\n",
    "    return path\n",
    "\n",
    "def csvToDataFrame(path):\n",
    "    feature = input('Tipo de feature a ser trabalhada: ')\n",
    "    df = pd.read_csv(path+'\\\\'+feature+'.csv')\n",
    "    df=df.drop(labels='Id',axis=1)\n",
    "    return df\n",
    "\n",
    "def getDatasetValues(df):\n",
    "    y = df.loc[:,'Tag'].tolist()\n",
    "    df = df.drop('Tag',axis=1)\n",
    "\n",
    "    X = df.values\n",
    "\n",
    "    Id = df.index.values\n",
    "\n",
    "    X, y, Id = shuffle(X, y, Id)\n",
    "    return (X, y, Id)\n",
    "\n",
    "def predictAndEvaluate(classifier, X, y, dataset_name, lc = 5,  n_jobs = 2, feature_selection = -1, save_model = False):\n",
    "\n",
    "    s = (np.linspace(0,1,lc+1) * len(y)).astype(np.int)[1:] #creates an array from 0.1 to 1 with 10 evenly spaced items, and multiply by the number of instances of the dataset\n",
    "\n",
    "    predicts = []\n",
    "    for val in s:\n",
    "        logger.info('cross evaluating with '+ str((val/len(y))*100) + '% of corpus')\n",
    "        if feature_selection > 0:\n",
    "            predicts.append( cross_val_predict(make_pipeline(SelectKBest(mutual_info_classif,feature_selection),classifier), X[:val], y[:val], cv=5, verbose=False, n_jobs=n_jobs) )\n",
    "        else:\n",
    "            predicts.append( cross_val_predict(classifier, X[:val], y[:val], cv=5,verbose=False, n_jobs=n_jobs) )\n",
    "\n",
    "\n",
    "    if save_model:\n",
    "        model_name = (classifier.__class__.__name__ + '_' + (dataset_name.split('\\\\')[-1].split('/')[-1].split('.')[0]) + '.pkl').lower()\n",
    "        classifier.fit(X, y)\n",
    "        joblib.dump(classifier,model_name)\n",
    "\n",
    "\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    base_path = definePathEvaluate(input('Quem é você? '))\n",
    "    df = csvToDataFrame(base_path)\n",
    "    print(getDatasetValues(df))\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
