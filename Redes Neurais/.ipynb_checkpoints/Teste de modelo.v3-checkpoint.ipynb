{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab852b7",
   "metadata": {},
   "source": [
    "### Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8400dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\anaconda\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\anaconda\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\anaconda\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\anaconda\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\anaconda\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\anaconda\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\anaconda\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\anaconda\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting pt-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.3.0/pt_core_news_sm-3.3.0-py3-none-any.whl (13.0 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\anaconda\\lib\\site-packages (from pt-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.62.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (21.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (58.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.20.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.26.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\anaconda\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.2.2-cp39-cp39-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\anaconda\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.2.2\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\anaconda\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\anaconda\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\anaconda\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Installing collected packages: Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: packaging in c:\\anaconda\\lib\\site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\anaconda\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.0-py2.py3-none-any.whl (167 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\anaconda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\anaconda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=b8e86242f4d820d3d53428e1a931f206f8690859b15d8f7919d27df1f5cca0fb\n",
      "  Stored in directory: c:\\users\\nakamura lucas\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.9.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.47.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas além do gerenciador Anaconda\n",
    "!pip install spacy\n",
    "!python -m spacy download pt_core_news_sm\n",
    "!pip install wordcloud\n",
    "!pip install gensim\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0730ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import spacy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f187c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9fb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "    name = input('escreva o nome do modelo a ser carregado:')\n",
    "    savedModel = load_model(name+'.h5')\n",
    "    with open('wordIndex.json') as f:\n",
    "        dicto = json.load(f)\n",
    "    savedModel.summary()\n",
    "    return savedModel, dicto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7899ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escreva o nome do modelo a ser carregado:normal-trunc-150e500-2dense-acc96\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 500, 100)          9235900   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,336,701\n",
      "Trainable params: 100,801\n",
      "Non-trainable params: 9,235,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "model, tokenizer.word_index = loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05c66c",
   "metadata": {},
   "source": [
    "### Notícias analisadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a19f8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_t = '''A defensora pública aposentada Cláudia Alvarim Barrozo, 59, gravada agredindo verbalmente entregadores negros, no último sábado (30), em vídeo em que chama um deles de 'macaco', em um condomínio de luxo de Niterói (RJ), tem cinco passagens anteriores pela polícia por injúria racial. Além disso, a reportagem do UOL apurou que as investigações tiveram início em 2014 e que há ainda uma sexta anotação policial antes do caso deste final de semana, mas por lesão corporal e constrangimento.\n",
    "\n",
    "Claudia Barrozo foi intimada a prestar esclarecimentos na tarde desta quinta-feira (5) na 81ª DP (Itaipu), porém alegou que já tinha \"compromissos\" e pediu para que a oitiva fosse adiada para a semana que vem.\n",
    "\n",
    "Hoje pela manhã, Eduardo Pessanha Marques e Jonathas de Souza Mendonça estiveram na delegacia para serem ouvidos novamente. \"A sensação que eu tive era de que eu estava em um filme, em uma novela e que aquilo não poderia estar acontecendo\", disse Eduardo, que gravou o vídeo flagrando o crime.\n",
    "\n",
    "De acordo com o delegado Carlos César Santos, atualmente \"as pessoas denunciam, não se calam, por isso a incidência [do crime de injúria racial] é maior hoje em dia\". Os agentes irão analisar imagens de câmeras de segurança.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b363c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_t = '''o podemos decidiu  expulsar o deputado federal carlos gaguim do partido após a polícia federal fazer buscas a apreensões no gabinete dele na câmara com isso a legenda abre espaço para receber a senadora expulsa pelo pmdb katia abreu por meio de nota a legenda informou que o afastamento do parlamentar já era algo acordado entre os filiados da sigla  ainda que o parlamentar tenha comunicado a conclusão de sua desfiliação para esta semana diante dos fatos noticiados hoje a executiva nacional do podemos solicita o imediato cancelamento de sua filiação dos quadros do partidoo partido que no passado chegou a cogitar lançar o parlamentar como candidato ao senado diz que apoia a investigação com a ampla apuração dos eventuais crimes cometidos e a consequente responsabilização dos envolvidos para que todos sejam punidos com o máximo rigor da lei independentemente de posição ou cargo ocupado'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ed4f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_t = '''O ex-juiz e ex-ministro Sergio Moro (União Brasil) defendeu nesta 5ª feira (26.mai.2022) a PRF (Polícia Rodoviária Federal) e disse que a atuação dos 2 agentes da corporação no caso do homem asfixiado em Sergipe é uma “exceção”. Genivaldo de Jesus Santos morreu depois de ser colocado, por policiais rodoviários federais, dentro do porta-malas de uma viatura com fumaça dentro.\n",
    "\n",
    "“Lamentável ação em Sergipe de 2 policiais da PRF. Mas que não se tome exceção como regra. Conheci de perto a PRF quando ministro. São profissionais valorosos e a violência policial é rara. Que tudo seja apurado e os culpados, punidos. Meus sentimentos à família do senhor Genivaldo”, escreveu no Twitter. \n",
    "\n",
    "Moro deixou o cargo de ministro da Justiça do governo Bolsonaro em abril de 2020 depois que o presidente demitiu o então diretor-geral da PF Maurício Valeixo, que havia sido escolhido pelo ex-juiz da Lava Jato. As declarações de Moro quando pediu demissão são a base de uma investigação sobre a suposta interferência política de Bolsonaro na PF.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "654d9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_t = '''Os Estados Unidos continuam em choque após a morte de 21 pessoas, entre elas 19 crianças, em um ataque em uma escola na cidade de Uvalde, no Texas. O presidente Joe Biden anunciou na quarta-feira (25) que iria ao estado nos próximos dias, onde políticos pró e contra armas se opõem.\n",
    "\n",
    "Eram 11h30 em Uvalde, no estado americano do Texas, quando Salvador Ramos começou a atirar em alunos e professores da escola de ensino fundamental Robb, matando 21 pessoas, entre elas 19 crianças, na terça-feira (24).\n",
    "\n",
    "Celeste estava no carro quando ouviu no rádio que um incidente estava acontecendo na escola de sua filha de 9 anos. A mãe de família, de 30 anos, correu para o local. Quando chegou, os policiais a impediram de entrar na escola e, na mesma hora, o atirador saiu do prédio e atirou na direção dos agentes.\n",
    "\"Ele saiu e começou a atirar em todo mundo. Eu fiquei com muito medo\", conta. Poucos minutos depois, tiros voltaram a ser ouvidos no interior do centro de ensino. A filha de Celeste ainda estava no prédio.\n",
    "\n",
    "\"Ela ficou escondida no banheiro o tempo todo. Ela tentou sair e ele atirou bem na frente dela. Então ela parou e se escondeu em outro lugar. Ela então viu o atirador correr e atirar e se escondeu durante 15 minutos e depois começou a correr para a primeira porta aberta\", conta Celeste, que conseguiu encontrar a filha viva.\n",
    "\n",
    "\"Nessa hora eu pulei, a agarrei e a coloquei dentro do meu carro. Então eu esperei que os filhos de duas amigas minhas saíssem, mas eles não saíram\", diz a mãe emocionada.\n",
    "\n",
    "Celeste acredita que o que aconteceu com ela e a filha foi um \"milagre\". Ela conhecia todas as crianças e não pode evitar se sentir culpada por sua filha ter sobrevivido. Por isso, ela decidiu depositar, diante do portão da escola, 19 bichos de pelúcia, um para cada vítima.\n",
    "\n",
    "\"Eu trago um bicho de pelúcia para cada um para que eles possam dormir com eles. Eles são tão pequenos. São bebês. Esta é para Eli\", diz mostrando um dos brinquedos. \"Era uma das filhas de uma amiga minha. Ela fazia sempre vídeos super fofos. A mãe dela é uma boa amiga\", contou ao enviado especial da RFI em Uvalde, David Thomson.\n",
    "\n",
    "\"Todas estas crianças eram conhecidas. Elas eram todas tão boas. Crianças inocentes. Bebês. Alguns vinham às festas da minha família. Outras eram filhos de amigos\", diz Celeste chocada com o que foi o pior ataque a um centro de ensino nos Estados Unidos, em 10 anos.\n",
    "\n",
    "\"Todo mundo se conhece aqui, é uma pequena comunidade. É simplesmente muito triste. Somos todos próximos. Minha vizinha perdeu a sobrinha e o sobrinho. Meu coração está partido porque minha filha também estava na escola, mas ela voltou para casa. As crianças de meus amigos não voltaram\", lamenta.\n",
    "\n",
    "No dia seguinte da matança, centenas de habitantes de Uvalde se reuniram para homenagear as vítimas. Orações, músicas e sofrimento marcaram a manifestação. Entre os presentes, um agente de polícia em uniforme, pai de uma vítima, arrasado, em lágrimas nos braços do senador Ted Cruz, que estava presente, assim como Greg Abott, governador do Texas.\n",
    "\n",
    "Uvalde é uma pequena comunidade rural de 16 mil habitantes, três quartos hispânicos. \"Estamos simplesmente chocados. Não conseguimos acreditar que uma coisa assim tenha acontecido em uma cidade tão pequena\", disse o pai de um aluno.\n",
    "\n",
    "\"Eu estou triste, simplesmente triste. Faltam palavras. Grotesco, desprezível. Eram crianças inocentes. Elas tinham a vida diante delas, um futuro. Tudo isso foi roubado\", disse outro pai de um sobrevivente.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcf9537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_f = '''Bolsonaro põe fim ao seu casamento e isolada ex-mulher O casamento de Michelle e Jair Bolsonaro chegou ao fim. O casal passa por uma crise complexa desde novembro de 2018, depois que Jair foi eleito Presidente do Brasil.\n",
    " \n",
    "O site de cobertura e fatos de celebridades e famosos, [site] foi o primeiro site a revelar a separação do casal no dia 13 de outubro de 2020. Na terça-feira o mesmo site revelou que a ex-primeira dama e esposa de Bolsonaro – Michelle Bolsonaro tem sofrido com o fim do casamento e se sentido isolada.\n",
    "\n",
    "O Custo da vila Olímpica do Japão: 29 milhões de dólares. O custo da vila Olímpica na olimpíada do Brasil: 900 milhões de dólares. e pra variar quem governava o Brasil na época: PT e Lula, quem ganhou muito dinheiro: políticos envolvidos na corrupção, e a globolixo\n",
    "\n",
    "NO RIO GRANDE DO SUL PRODUTORES DE UVA TOMAM MEDIDAS PARA EVITAR A GEADA NO RIO GRANDE DO SUL PRODUTORES DE UVA TOMAM MEDIDAS PARA EVITAR A GEADA Conforme informações do diário da informação em Bento Gonçalves para não congelar as uvas os produtores estão utilizando o fogo em tonéis, a técnica já é usada há alguns anos no Brasil e em outros países. Além da proteção é mais um espetáculo na Serra Gaúcha.\n",
    "\n",
    "Lula admite DERROTA em discurso de 1º de Maio. O discurso de Lula que era para ser às 12:00hs foi mudado para às 13:00 e só começou às 15:30. Tudo porque não tinha gente o suficiente. No discurso Lula diz que ainda não é candidato. Ele disse: “só dia 7 eu vou ser pré-candidato”. Será que já arregou?\n",
    "\n",
    "Bolsonaro põe fim ao seu casamento e isolada ex-mulher O casamento de Michelle e Jair Bolsonaro chegou ao fim. O casal passa por uma crise complexa desde novembro de 2018, depois que Jair foi eleito Presidente do Brasil.\n",
    " \n",
    "O site de cobertura e fatos de celebridades e famosos, [site] foi o primeiro site a revelar a separação do casal no dia 13 de outubro de 2020. Na terça-feira o mesmo site revelou que a ex-primeira dama e esposa de Bolsonaro – Michelle Bolsonaro tem sofrido com o fim do casamento e se sentido isolada.\n",
    "\n",
    "O Custo da vila Olímpica do Japão: 29 milhões de dólares. O custo da vila Olímpica na olimpíada do Brasil: 900 milhões de dólares. e pra variar quem governava o Brasil na época: PT e Lula, quem ganhou muito dinheiro: políticos envolvidos na corrupção, e a globolixo\n",
    "\n",
    "NO RIO GRANDE DO SUL PRODUTORES DE UVA TOMAM MEDIDAS PARA EVITAR A GEADA NO RIO GRANDE DO SUL PRODUTORES DE UVA TOMAM MEDIDAS PARA EVITAR A GEADA Conforme informações do diário da informação em Bento Gonçalves para não congelar as uvas os produtores estão utilizando o fogo em tonéis, a técnica já é usada há alguns anos no Brasil e em outros países. Além da proteção é mais um espetáculo na Serra Gaúcha.\n",
    "\n",
    "Lula admite DERROTA em discurso de 1º de Maio. O discurso de Lula que era para ser às 12:00hs foi mudado para às 13:00 e só começou às 15:30. Tudo porque não tinha gente o suficiente. No discurso Lula diz que ainda não é candidato. Ele disse: “só dia 7 eu vou ser pré-candidato”. Será que já arregou?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c7b6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_t = 'Os estudantes da cidade de São Carlos desenvolveram uma nova solução para classificação de fake news e para verificação do nível de embriaguez durante o TUSCA.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969ce4a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f864bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o pacote de língua portuguesa para o processador Spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6567ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defininido funções de preprocessamento\n",
    "\n",
    "def removePunct(text):\n",
    "    '''\n",
    "    Removes any punctuation included in string.punctuation.\n",
    "    '''\n",
    "    translator = text.maketrans({key:'' for key in string.punctuation+'“”'}) # Translates any punctuation into ''\n",
    "    return text.translate(translator)\n",
    "\n",
    "def removeNumbers(text):\n",
    "    '''\n",
    "    Removes any number character in text.\n",
    "    '''\n",
    "    return re.sub('[0-9]', '' , text) # Translates any number into ''\n",
    "\n",
    "def removeStopWords(string):\n",
    "    '''\n",
    "    Removes any portuguese stopwords, using Spacy's standard package.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    Lemmatizes text word-by-word. Notice that lemmatizing is not as harsh as stemming, which makes the final text easier to read and understand in common language.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "def prep(string, useStopWords = False, lemma = False):\n",
    "    '''\n",
    "    Executes previously defined preprocessing in text.\n",
    "    '''\n",
    "\n",
    "    result = removeNumbers(removePunct(string)).lower()\n",
    "    \n",
    "    if useStopWords and lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc if token.is_stop is False])\n",
    "    elif useStopWords:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "    elif lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "    result = result.replace('\\n',\"\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc8b129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'os estudantes da cidade de são carlos desenvolveram uma nova solução para classificação de fake news e para verificação do nível de embriaguez durante o tusca'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_t = prep(sentence_t)\n",
    "sentence_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a997a",
   "metadata": {},
   "source": [
    "### Classificação Trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f06eb3ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lista_t = []\n",
    "lista_t.append(sentence_t)\n",
    "lista_t\n",
    "\n",
    "maxlen = 500\n",
    "sequences_t = tokenizer.texts_to_sequences(lista_t)\n",
    "padded_t = pad_sequences(sequences_t, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "219e9eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Notícia Verdadeira\n"
     ]
    }
   ],
   "source": [
    "model.predict(padded_t)\n",
    "\n",
    "if (model.predict(padded_t) >=0.5).astype(int) == 1:\n",
    "    print('Notícia Falsa')\n",
    "else:\n",
    "    print('Notícia Verdadeira')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41053826",
   "metadata": {},
   "source": [
    "### Classificação Fakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5f0d579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quatro expresidentes presos até é o que a lava jato está preparando a força tarefa da operação lava jato está com farto material acusatório para levar para a cadeia simultaneamente expresidentes do brasil lula dilma temer e collor podem terminar sua vida política atrás das gradesa condenação de lula acendeu o alerta vermelho em políticos que se achavam intocáveis a operação lava jato ao condenar o maior líder político da esquerda no brasil demonstrou que nenhuma pessoa está acima da leia condenação a nove anos e seis meses de prisão pelo juiz federal sergio moro nesta quartafeira não mandará o petista automaticamente para a cadeia isso porque moro é um juiz de primeira instância e assim sua decisão não basta para que a pena seja cumprida imediatamentetoda decisão que o \\x93juiz da lava jato\\x94 toma em primeira instância é depois revisada em segunda instância pelos desembargadores do tribunal regional da a região trf joão pedro gebran neto relator da operação leandro paulsen e victor luiz dos santos laus membros da a turma da corte sediada em porto alegreo trio da segunda instância é muito mais duro que o juiz sergio moro a pena de lula provavelmente será confirmada e ampliada ele ficará fora das eleições de e com ele levará mais três expresidentes que lhe foram muito próximos durante os anos em que o petismo conduziu os rumos políticos do brasilpesa sobre michel temer fortíssimos indícios de corrupção passiva organização criminosa e obstrução de justiça somente com as provas levantadas até agora ele pode pegar até anos de cadeiacontra dilma vana rousseff pesa mais fortemente a acusação de tentativa de obstrução da justiça tal acusação fundamenta pela policia federal do brasil aponta tentativa de blindar o expresidente lula e barrar os processos em que ele está envolvido na operação lava jato ao nomeálo como ministroembora contra dilma ainda existam investigações sobre o caixa dois em suas campanhas eleitorais ela é a que possui mais chances de se livrar das garras da justiça caso seja condenada por obstrução da justiça sua pena será de até anos de reclusão como as penas inferiores a anos de reclusão são substituídas por penas são substituídas por prestação de serviços a comunidade ela precisa de mais uma condenação para de fato se juntar ao time dos expresidentes presoso expresidente fernando collor de melo ptcal é acusado pela procuradoriageral da república de ter recebido ao menos r milhões em propinas entre e referentes a dois contratos da br distribuidora subsidiária da petrobrás que segundo revelaram as investigações da lava jato também teria sido palco de um esquema de corrupção e loteamento de cargos políticos de maneira similar ao que ocorreu na estatal petrolíferaagora collor tem um conjunto pesado de acusações de peculato e lavagem de dinheiro pode ser condenado a anos de cadeia em regime fechadocomo podemos notar a operação lava jato está passando a limpo a história do brasil se os políticos não abafarem a operação teremos uma depuração dos processos políticos e um novo brasil surgindo das cinzas']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_f = []\n",
    "lista_f.append(sentence_f)\n",
    "lista_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f930e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "sequences_f = tokenizer.texts_to_sequences(lista_f)\n",
    "padded_f = pad_sequences(sequences_f, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a50a1266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9640597]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbbaeaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(padded_f) >=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
