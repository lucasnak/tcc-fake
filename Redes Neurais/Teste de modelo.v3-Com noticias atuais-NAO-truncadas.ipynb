{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab852b7",
   "metadata": {},
   "source": [
    "### Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199344c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0730ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6cdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Viabilizadores\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Feature selection & relatório de resultados\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import classification_report , confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f187c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef9fb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "    name = input('escreva o nome do modelo a ser carregado:')\n",
    "    savedModel = load_model(name)\n",
    "    with open('wordIndex.json') as f:\n",
    "        dicto = json.load(f)\n",
    "    savedModel.summary()\n",
    "    return savedModel, dicto\n",
    "\n",
    "def loadTraditional():\n",
    "    name = input('escreva o nome do modelo a ser carregado:')\n",
    "    savedModel = joblib.load(name)\n",
    "    print(\"model loaded\")\n",
    "    return savedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "34747544",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escreva o nome do modelo a ser carregado:SVC_7200_news_certo.pkl\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model=loadTraditional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899ce69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "model, tokenizer.word_index = loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05c66c",
   "metadata": {},
   "source": [
    "### Notícias analisadas - True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1bde219",
   "metadata": {},
   "outputs": [],
   "source": [
    "true=[]\n",
    "for i in range(1,54):\n",
    "    try:\n",
    "        with open(r'C:\\Users\\vduchi01\\Downloads\\tcc-fake-main\\tcc-fake-main\\3.noticias_true_maio22\\\\'+str(i)+'.txt', encoding =\"utf8\") as t:\n",
    "            true.append(t.read())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "202d9c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true) # Ainda não truncado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a42402a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bd23669",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'true',\n",
       " 'fake',\n",
       " 'fake',\n",
       " 'fake']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_2 = ['true' if item == 0 else 'fake' for item in labels]\n",
    "labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0698fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame(list(zip(true,labels)),columns=['true','labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969ce4a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f864bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o pacote de língua portuguesa para o processador Spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6567ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defininido funções de preprocessamento\n",
    "\n",
    "def removePunct(text):\n",
    "    '''\n",
    "    Removes any punctuation included in string.punctuation.\n",
    "    '''\n",
    "    translator = text.maketrans({key:'' for key in string.punctuation+'“”'}) # Translates any punctuation into ''\n",
    "    return text.translate(translator)\n",
    "\n",
    "def removeNumbers(text):\n",
    "    '''\n",
    "    Removes any number character in text.\n",
    "    '''\n",
    "    return re.sub('[0-9]', '' , text) # Translates any number into ''\n",
    "\n",
    "def removeStopWords(string):\n",
    "    '''\n",
    "    Removes any portuguese stopwords, using Spacy's standard package.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    Lemmatizes text word-by-word. Notice that lemmatizing is not as harsh as stemming, which makes the final text easier to read and understand in common language.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "def prep(string, useStopWords = True, lemma = True):\n",
    "    '''\n",
    "    Executes previously defined preprocessing in text.\n",
    "    '''\n",
    "\n",
    "    result = removeNumbers(removePunct(string)).lower()\n",
    "    \n",
    "    if useStopWords and lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc if token.is_stop is False])\n",
    "    elif useStopWords:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "    elif lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "    result = result.replace('\\n',\"\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70f23fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_t = df['true'].apply(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "026975d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_t[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3c8ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    presidente jair bolsonaro dizer caso avancar d...\n",
       "1    comissão constituição Justiça Câmara ccj adiar...\n",
       "2    deputado anunciar mesmo sessão acordo firmar A...\n",
       "3    comissão constituição Justiça ccj senado adiar...\n",
       "4    centro contingência coronavírus Paulo voltar r...\n",
       "Name: true, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a997a",
   "metadata": {},
   "source": [
    "### Classificação Trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2275c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_t = sentence_t.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cea03779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comissão constituição Justiça Câmara ccj adiar terçafeira   votação requerimento convocação ministro Justiça Anderson Torres explique assassinato genivaldo jesus santo abordagem polícia Rodoviária federal prf Sergipe  presidente colegiado Arthur Maia uniãoba retirar proposta ofício autor matéria deputado delegado waldir uniãogo comparecer motivo saúde  regimento casa exigir presença autor proposta ser votar deputado afirmar tradição adotar ccj – caber autor encaminhar defesa votação requerimento  delegar waldir afirmar tv globo recuperar Covid aceitar pressão governo matéria ser votar parlamentar acreditar tema ser votar semana  imprescindível sociedade brasileiro ministro ir ccj acontecer dizer delegado waldir  praxe governo articule pedido convocação – presença autoridade obrigatório data hora marcar – ser converter convite – presença facultativo agendamento negociar autoridade  caso convocação ser aprovar anderson Torres ser comparecer justificar ausência contrário responder crime responsabilidade  genivaldo morrer abordagem policial rodoviário federal município umbaúba sul Sergipe cerca   km Aracaju  imagem mostrar genivaldo imobilizar colocar portamalas viatura imagem carro tomado fumaça branco vídeo acima  requerimento analisar ccj pedir ministro explique  operação polícia militar Rio prf deixar   morto vila cruzeiro juramento semana passado  morte agente prf durante ocorrência acidente trânsito br fortaleza  operação padrão adotar categoria demandar recomposição salarial  haver requerimento convocação Anderson Torres falar morte genivaldo comissão direito humano casa sessão marcar quartafeira º  comissão analisar convite comparecimento diretor prf silvinar vasque – contrário Ministros silvinei convocar '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bedb47e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06eb3ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "sequences_t = tokenizer.texts_to_sequences(sentence_t)\n",
    "padded_t = pad_sequences(sequences_t, maxlen=maxlen, padding='post',truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a69f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(padded_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368700e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,50):\n",
    "    print(len(sequences_t[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161a733",
   "metadata": {},
   "source": [
    "Rodar no Tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82896d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_2 = [item.split() for item in lista_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c386d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_3 = [noticia[0:100] for noticia in lista_2] #if len(noticia)>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,53):\n",
    "    print(len(lista_3[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [x for xs in lista_3 for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4718d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf1303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_4=[]\n",
    "for i in lista_3:\n",
    "    lista_4.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2644e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeMinFreq(data, features, min_freq = 1):\n",
    "    # Realiza a soma da frequência de cada palavra da matriz vetorizada\n",
    "    cols_sum = np.sum(data, axis=0)\n",
    "\n",
    "    del_indexes = []\n",
    "    # Analisa cada valor das contagens de frequência do cols_sum, assignando um índice i, e salva o índice em del_indexes[]\n",
    "    # quando a contagem for acima da min_freq\n",
    "    for i, val in zip(range(len(cols_sum)), cols_sum):\n",
    "        if val < min_freq:\n",
    "            del_indexes.append(i)\n",
    "            \n",
    "    data = np.delete(data,del_indexes,1) # Deleta coluna\n",
    "    features = np.delete(features,del_indexes,0) # Deleta linha\n",
    "    return (data, features)\n",
    "\n",
    "\n",
    "def normalizeData(data):\n",
    "    rows_sum = np.sum(data, axis=1)\n",
    "    data = (data.T / rows_sum).T\n",
    "    return data\n",
    "\n",
    "def loadCount(texts, min_freq = 1, binary = False, normalize = True):\n",
    "\n",
    "    # Instanciando o CountVectorizer\n",
    "    vectorizer = CountVectorizer(input = 'content', preprocessor = prep, encoding='utf-8', binary = binary);\n",
    "    \n",
    "    # Aplicando processo de vetorização\n",
    "    data = np.array(vectorizer.fit_transform(lista_t).todense());\n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    # Se min_freq for 1, então todos os tokens são considerados\n",
    "    if(min_freq > 1):\n",
    "        data, features = removeMinFreq(data, features, min_freq)\n",
    "    if(normalize):\n",
    "        data = normalizeData(data)\n",
    "\n",
    "    return pd.DataFrame(data,columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "105e96b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bow = loadCount(lista_t, normalize = False)\n",
    "#df_tfidf = loadTfidf(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2886c85",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    1\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "40    0\n",
      "41    0\n",
      "42    0\n",
      "43    0\n",
      "44    0\n",
      "45    0\n",
      "46    0\n",
      "47    0\n",
      "48    0\n",
      "49    0\n",
      "50    0\n",
      "51    0\n",
      "52    0\n",
      "Name: Abril, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_bow['Abril'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "277e12c5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "30    0\n",
       "31    0\n",
       "32    0\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "36    0\n",
       "37    0\n",
       "38    0\n",
       "39    0\n",
       "40    0\n",
       "41    0\n",
       "42    0\n",
       "43    0\n",
       "44    0\n",
       "45    0\n",
       "46    0\n",
       "47    0\n",
       "48    0\n",
       "49    0\n",
       "50    1\n",
       "51    1\n",
       "52    1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6480c759",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_selection = 100\n",
    "\n",
    "X_best = SelectKBest(mutual_info_classif,k=feature_selection).fit_transform(df_bow,df['labels'])\n",
    "\n",
    "predictions = (cross_val_predict(model, X_best, df['labels'], cv=3)) # Will return 0 and 1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c57cf416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictions = model.predict(X_best) # Will return fake and true strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2673209d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Falsas       0.94      1.00      0.97        50\n",
      " Verdadeiras       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94        53\n",
      "   macro avg       0.47      0.50      0.49        53\n",
      "weighted avg       0.89      0.94      0.92        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vduchi01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vduchi01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vduchi01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_name = ['Falsas','Verdadeiras']\n",
    "print(classification_report(labels, predictions, target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=labels_2,predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd57a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10,7))\n",
    "sns.heatmap(data=cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a98c7",
   "metadata": {},
   "source": [
    "Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ed30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = (model.predict(padded_t) >=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530de1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f39118",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,50):\n",
    "    print(y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90826581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(labels, y_pred))\n",
    "print(precision_score(labels, y_pred))\n",
    "print(recall_score(labels, y_pred))\n",
    "print(f1_score(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba50e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = ['Verdadeiras','Falsas']\n",
    "print(classification_report(labels, y_pred, target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b42dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=labels,predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b339b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10,7))\n",
    "sns.heatmap(data=cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41053826",
   "metadata": {},
   "source": [
    "### Classificação Fakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_f = []\n",
    "lista_f.append(sentence_f)\n",
    "lista_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f930e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "sequences_f = tokenizer.texts_to_sequences(lista_f)\n",
    "padded_f = pad_sequences(sequences_f, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(padded_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbaeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(padded_f) >=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
