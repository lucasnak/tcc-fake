{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd19757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\vitor\\anaconda3\\lib\\site-packages (3.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting pt-core-news-sm==3.2.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 08:49:36.558273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-13 08:49:36.560396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.2.0/pt_core_news_sm-3.2.0-py3-none-any.whl (22.2 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pt-core-news-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.1.1)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.2.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas além do gerenciador Anaconda\n",
    "!pip install spacy\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos básicos para manuseio de dados e arquivos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Módulo para visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Módulos para processamento de linguagem\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8cb9d6",
   "metadata": {},
   "source": [
    "## Carregamento de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b0955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_news_path = r'Software\\Fake.br-Corpus' #\\fake_10 or \\true_10\n",
    "news_path = r'Software\\Fake.br-Corpus\\full_texts' #\\fake or \\true\n",
    "\n",
    "paths = [limited_news_path, news_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017b5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDir(dir_path: str, is_meta=False) ->list:\n",
    "    '''\n",
    "    Ordena os arquivos dentro de dir_path e os retorna no formato de lista.\n",
    "    '''\n",
    "    if is_meta:\n",
    "        number_separator = \"-meta.txt\"\n",
    "    else:\n",
    "        number_separator = \".txt\"\n",
    "\n",
    "    first_list = os.listdir(dir_path)\n",
    "    int_list = [int(element.split(number_separator)[0]) for element in first_list]\n",
    "    int_list.sort()\n",
    "    final_list = [(str(element) + number_separator) for element in int_list]\n",
    "\n",
    "    return final_list\n",
    "\n",
    "def txtToDataframe(path, is_limited=True):\n",
    "    '''\n",
    "    Function for converting full texts to a single DataFrame.\n",
    "    '''\n",
    "    if is_limited:\n",
    "        true_files = [path+\"\\\\true_10\\\\\"+f for f in sortDir(dir_path = path+'\\\\true_10') if isfile(join(path+'\\\\true_10', f))]\n",
    "        fake_files = [path+\"\\\\fake_10\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake_10') if isfile(join(path+'\\\\fake_10', f))]\n",
    "    else:\n",
    "        true_files = [path+\"\\\\true\\\\\"+f for f in sortDir(dir_path = path+'\\\\true') if isfile(join(path+'\\\\true', f))]\n",
    "        fake_files = [path+\"\\\\fake\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake') if isfile(join(path+'\\\\fake', f))]\n",
    "    \n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in true_files:\n",
    "        with open(file, encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append('true')\n",
    "    for file in fake_files:\n",
    "        with open(file, encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append('fake')\n",
    "            \n",
    "    df = pd.DataFrame(list(zip(texts,labels)),columns=['texts','labels'])\n",
    "    \n",
    "    # Com esta função, textos e labels foram inseridos em um DataFrame de maneira sequencial. Todas as notícias verdadeiras vêm\n",
    "    # ANTES do bloco de notícias falsas.\n",
    "    \n",
    "    return df\n",
    "\n",
    "def appendMetadata(path,df, is_limited=True):\n",
    "    '''\n",
    "    Function for appending metadata to previously generated news DataFrame.\n",
    "    '''\n",
    "    if is_limited:\n",
    "        true_meta = [path+\"\\\\true-meta-information-10\\\\\"+f for f in sortDir(dir_path = path+'\\\\true-meta-information-10',is_meta=True) if isfile(join(path+'\\\\true-meta-information-10', f))]\n",
    "        fake_meta = [path+\"\\\\fake-meta-information-10\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake-meta-information-10',is_meta=True) if isfile(join(path+'\\\\fake-meta-information-10', f))]\n",
    "    else:\n",
    "        true_meta = [path+\"\\\\true-meta-information\\\\\"+f for f in sortDir(dir_path = path+'\\\\true-meta-information',is_meta=True) if isfile(join(path+'\\\\true-meta-information', f))]\n",
    "        fake_meta = [path+\"\\\\fake-meta-information\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake-meta-information',is_meta=True) if isfile(join(path+'\\\\fake-meta-information', f))]\n",
    "    \n",
    "\n",
    "    #true_meta e fake_meta são listas com todas os paths para arquivos de metadata.\n",
    "    \n",
    "    columns = [\"author\", \"source\", \"category\", \"date\",\"tokens\",\"words_without_punctuation\",\"types\",\"number_of_links\",\"uppercase_words\",\"verbs\",\"subjuntive_imperative\",\"nouns\",\"adjectives\",\"adverbs\",\"modal_verbs\",\"singular_first_and_second_personal_pronouns\",\"plural_first_personal_pronouns\",\"pronouns\",\"pausality\",\"characters\",\"avg_sentence_length\",\"avg_word_length\",\"percentage_of_spelling_errors\",\"emotiveness\",\"diversity\"]\n",
    "    \n",
    "    true_metadata = pd.DataFrame(columns=columns)\n",
    "    fake_metadata = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for file in true_meta:\n",
    "        #print(file)\n",
    "        aux = pd.read_csv(file, header=None, sep = '\\n').transpose()\n",
    "        aux.columns = columns\n",
    "        true_metadata=true_metadata.append(aux)\n",
    "        \n",
    "        \n",
    "    for file in fake_meta:\n",
    "        #print(file)\n",
    "        aux = pd.read_csv(file, header=None, sep = '\\n').transpose()\n",
    "        aux.columns = columns\n",
    "        fake_metadata=fake_metadata.append(aux)\n",
    "        \n",
    "    \n",
    "    metadata = pd.DataFrame(columns=columns)\n",
    "    metadata = metadata.append(true_metadata,ignore_index=True)\n",
    "    metadata = metadata.append(fake_metadata,ignore_index=True) \n",
    "\n",
    "\n",
    "    complete_df = pd.concat([df,metadata],axis=1)\n",
    "    # Este DataFrame possui todos os textos/labels (2 colunas) e metadata (25 colunas).\n",
    "    \n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f5bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Base com 10 notícias verdadeiras e 10 notícias falsas\n",
      "1 - Base completa de notícias\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ai = int(input('''0 - Base com 10 notícias verdadeiras e 10 notícias falsas\n",
    "1 - Base completa de notícias\n",
    "'''))\n",
    "\n",
    "path = paths[ai]\n",
    "\n",
    "if ai == 0:\n",
    "    data = txtToDataframe(path) # Dataframe contendo notícias e labels.\n",
    "    complete_data = appendMetadata(path,data) # Dataframe contendo notícias, labels e metadata.\n",
    "else:\n",
    "    data = txtToDataframe(path,is_limited=False)\n",
    "    complete_data = appendMetadata(path,data,is_limited=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0bff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c597e091",
   "metadata": {},
   "source": [
    "## Analisando Base de notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7070d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando tamanho de notícias (plotar histograma contendo as quantidades de notícias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259eaf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificando assuntos\n",
    "\n",
    "ax = complete_data['category'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(5,3),\n",
    "                                    title=\"Quantidade de notícias total por categoria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8c571",
   "metadata": {},
   "source": [
    "## Extraindo features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5718d62",
   "metadata": {},
   "source": [
    "##### Bag-of-words\n",
    "O Bag-of-words realiza uma contagem da quantidade de palavras existentes em um conjunto grande de textos. Para utilizar o efeito de considerar palavras com o mesmo significado, devemos pré-processar os textos e lematizar cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b597d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o pacote de língua portuguesa para o processador Spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d839fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4807c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defininido funções de preprocessamento\n",
    "\n",
    "def removePunct(text):\n",
    "    '''\n",
    "    Removes any punctuation included in string.punctuation.\n",
    "    '''\n",
    "    translator = text.maketrans({key:'' for key in string.punctuation}) # Translates any punctuation into ''\n",
    "    return text.translate(translator)\n",
    "\n",
    "def removeNumbers(text):\n",
    "    '''\n",
    "    Removes any number character in text.\n",
    "    '''\n",
    "    return re.sub('[0-9]', '' , text) # Translates any number into ''\n",
    "\n",
    "def removeStopWords(string):\n",
    "    '''\n",
    "    Removes any portuguese stopwords, using Spacy's standard package.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    Lemmatizes text word-by-word. Notice that lemmatizing is not as harsh as stemming, which makes the final text easier to read and understand in common language.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "def prep(string, useStopWords = True, lemma = True):\n",
    "    '''\n",
    "    Executes previously defined preprocessing in text.\n",
    "    '''\n",
    "\n",
    "    result = removeNumbers(removePunct(string)).lower()\n",
    "    \n",
    "    if useStopWords and lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc if token.is_stop is False])\n",
    "    elif useStopWords:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "    elif lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0bfd933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlos vir pra zonear \n",
      " esporte bostar negócio cachaça ganhar apanhar ir brindar \n",
      " pingar querer limãaaaaao mulher tesãaaaaao dia eesc amar precisar macacada puta merda cagar \n",
      " legal calcular integral grafitar calcular limitar\n"
     ]
    }
   ],
   "source": [
    "text = '''Nós somos lá de São Carlos, viemos aqui pra zonear.\n",
    "No esporte, nós somos bosta, nosso negócio é a cachaça. E mesmo, que nós não ganhe, que nós apanhe, vamos brindar.\n",
    "A pinga, queremos com limãaaaaao. Mulheres, com muito mais tesãaaaaao. Se um dia a EESC amada precisar da macacada, puta merda, que cagada, 1,2,3,4.\n",
    "Como é legal, calcular a integral. Mesmo sem grafite, calculamos o limite.'''\n",
    "\n",
    "print(prep(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8843e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petrobras anunciar segundafeira   elevar preço diesel distribuidor preço médio litro passar r   r   terço   aumentar \n",
      "\n",
      " preço gasolina gás cozinhar ser alterar \n",
      "\n",
      " petroleiro diesel sofrer reajustar haver   dia –   março petrobras alto refletia elevação observar preço mercar\n"
     ]
    }
   ],
   "source": [
    "text_news = '''A Petrobras anunciou nesta segunda-feira (9) que vai elevar o preço do diesel para as distribuidoras. O preço médio do litro vai passar de R$ 4,51 para R$ 4,91 a partir de terça (10), um aumento de 8,87%.\n",
    "\n",
    "Os preços da gasolina e do gás de cozinha não serão alterados.\n",
    "\n",
    "Segundo a petroleira, o diesel não sofria reajuste há 60 dias – desde 11 de março. Naquele momento, diz a Petrobras, a alta refletia \"apenas parte da elevação observada nos preços de mercado\".'''\n",
    "\n",
    "print(prep(text_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81296d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeMinFreq(data, features, min_freq = 1):\n",
    "    # Realiza a soma da frequência de cada palavra da matriz vetorizada\n",
    "    cols_sum = np.sum(data, axis=0)\n",
    "\n",
    "    del_indexes = []\n",
    "    # Analisa cada valor das contagens de frequência do cols_sum, assignando um índice i, e salva o índice em del_indexes[]\n",
    "    # quando a contagem for acima da min_freq\n",
    "    for i, val in zip(range(len(cols_sum)), cols_sum):\n",
    "        if val < min_freq:\n",
    "            del_indexes.append(i)\n",
    "            \n",
    "    data = np.delete(data,del_indexes,1) # Deleta coluna\n",
    "    features = np.delete(features,del_indexes,0) # Deleta linha\n",
    "    return (data, features)\n",
    "\n",
    "\n",
    "def normalizeData(data):\n",
    "    rows_sum = np.sum(data, axis=1)\n",
    "    data = (data.T / rows_sum).T\n",
    "    return data\n",
    "\n",
    "\n",
    "def loadCount(texts, min_freq = 1, binary = False, normalize = True):\n",
    "\n",
    "    # Instanciando o CountVectorizer\n",
    "    vectorizer = CountVectorizer(input = 'content', preprocessor = prep, encoding='utf-8', binary = binary);\n",
    "    \n",
    "    # Aplicando processo de vetorização\n",
    "    data = np.array(vectorizer.fit_transform(text_list).todense());\n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    # Se min_freq for 1, então todos os tokens são considerados\n",
    "    if(min_freq > 1):\n",
    "        data, features = removeMinFreq(data, features, min_freq)\n",
    "    if(normalize):\n",
    "        data = normalizeData(data)\n",
    "\n",
    "    return pd.DataFrame(data,columns = features)\n",
    "\n",
    "def loadTfidf(texts):\n",
    "\n",
    "    # Instanciando o Tf-Idf como vetorizador\n",
    "    vectorizer = TfidfVectorizer(input = 'content', preprocessor = prep, encoding='utf-8')\n",
    "    \n",
    "    data = np.array(vectorizer.fit_transform(texts).todense());\n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    return pd.DataFrame(data,columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463404f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando as funções definidas previamente, criamos dataframes para o bag-of-words (frequência geral e TF-IDF).\n",
    "\n",
    "text_list = complete_data['texts'].to_list()\n",
    "\n",
    "df_bow = loadCount(text_list, normalize = False)\n",
    "df_tfidf = loadTfidf(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e0b65",
   "metadata": {},
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a2f1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulos para modelagem de aprendizado de máquina tradicionais\n",
    "\n",
    "# Viabilizadores\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Algoritmos\n",
    "from sklearn.svm import SVC #, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature selection & relatório de resultados\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import classification_report , confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611ecfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignVariables(df_features, df_complete_data):\n",
    "    X = df_features.values\n",
    "    y = df_complete_data['labels']\n",
    "    \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9330f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignando variáveis dependentes e independentes e dividindo dados em conjunto de teste e treino\n",
    "\n",
    "X,y = assignVariables(df_bow,complete_data)\n",
    "\n",
    "test_size = 0.20\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b0b0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1368)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ccde8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1368)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb035a1d",
   "metadata": {},
   "source": [
    "### Selecione um algoritmo:\n",
    "0 - Logistic Regression  \n",
    "1 - Naive Bayes  \n",
    "2 - Gradient Boosting  \n",
    "3 - Random Forests  \n",
    "4 - Support Vector Machine (SVM)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3323ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_best.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4db26ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d88bf66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insira o ID do algoritmo a ser usado para treinamento do modelo: 1\n",
      "Salvar modelo?\n",
      "0 - Não\n",
      "1 - Sim\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Texto       0.75      0.60      0.67        10\n",
      "       Label       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.71      0.70      0.70        20\n",
      "weighted avg       0.71      0.70      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = [LogisticRegression(), MultinomialNB(), GradientBoostingClassifier(), RandomForestClassifier(), SVC()]\n",
    "\n",
    "choice = input(\"Insira o ID do algoritmo a ser usado para treinamento do modelo: \")\n",
    "save_model = int(input('''Salvar modelo?\n",
    "0 - Não\n",
    "1 - Sim\n",
    "'''))\n",
    "\n",
    "classifier = classifier[int(choice)]\n",
    "\n",
    "feature_selection = 100\n",
    "\n",
    "X_best = SelectKBest(mutual_info_classif,k=feature_selection).fit_transform(X,y)\n",
    "\n",
    "predictions = (cross_val_predict(classifier, X_best, y, cv=5))\n",
    "\n",
    "dataset_name = str(X.shape[0])+'_news'\n",
    "if save_model==1:\n",
    "    model_name = (classifier.__class__.__name__ + '_' + (dataset_name + '.pkl').lower())\n",
    "    classifier.fit(X_best, y)\n",
    "    joblib.dump(classifier,model_name)\n",
    "\n",
    "target_name = ['Texto','Label']\n",
    "print(classification_report(y, predictions, target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5618d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
