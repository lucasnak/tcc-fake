{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd19757",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\vitor\\anaconda3\\lib\\site-packages (3.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting pt-core-news-sm==3.2.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 08:49:36.558273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-13 08:49:36.560396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.2.0/pt_core_news_sm-3.2.0-py3-none-any.whl (22.2 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pt-core-news-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->pt-core-news-sm==3.2.0) (1.1.1)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.2.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas além do gerenciador Anaconda\n",
    "!pip install spacy\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549a2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos básicos para manuseio de dados e arquivos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Módulo para visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Módulos para processamento de linguagem\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8cb9d6",
   "metadata": {},
   "source": [
    "## Carregamento de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b0955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_news_path = r'Software\\Fake.br-Corpus' #\\fake_10 or \\true_10\n",
    "news_path = r'Software\\Fake.br-Corpus\\full_texts' #\\fake or \\true\n",
    "\n",
    "paths = [limited_news_path, news_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017b5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDir(dir_path: str, is_meta=False) ->list:\n",
    "    '''\n",
    "    Ordena os arquivos dentro de dir_path e os retorna no formato de lista.\n",
    "    '''\n",
    "    if is_meta:\n",
    "        number_separator = \"-meta.txt\"\n",
    "    else:\n",
    "        number_separator = \".txt\"\n",
    "\n",
    "    first_list = os.listdir(dir_path)\n",
    "    int_list = [int(element.split(number_separator)[0]) for element in first_list]\n",
    "    int_list.sort()\n",
    "    final_list = [(str(element) + number_separator) for element in int_list]\n",
    "\n",
    "    return final_list\n",
    "\n",
    "def txtToDataframe(path, is_limited=True):\n",
    "    '''\n",
    "    Function for converting full texts to a single DataFrame.\n",
    "    '''\n",
    "    if is_limited:\n",
    "        true_files = [path+\"\\\\true_10\\\\\"+f for f in sortDir(dir_path = path+'\\\\true_10') if isfile(join(path+'\\\\true_10', f))]\n",
    "        fake_files = [path+\"\\\\fake_10\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake_10') if isfile(join(path+'\\\\fake_10', f))]\n",
    "    else:\n",
    "        true_files = [path+\"\\\\true\\\\\"+f for f in sortDir(dir_path = path+'\\\\true') if isfile(join(path+'\\\\true', f))]\n",
    "        fake_files = [path+\"\\\\fake\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake') if isfile(join(path+'\\\\fake', f))]\n",
    "    \n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in true_files:\n",
    "        with open(file, encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append('true')\n",
    "    for file in fake_files:\n",
    "        with open(file, encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "            labels.append('fake')\n",
    "            \n",
    "    df = pd.DataFrame(list(zip(texts,labels)),columns=['texts','labels'])\n",
    "    \n",
    "    # Com esta função, textos e labels foram inseridos em um DataFrame de maneira sequencial. Todas as notícias verdadeiras vêm\n",
    "    # ANTES do bloco de notícias falsas.\n",
    "    \n",
    "    return df\n",
    "\n",
    "def appendMetadata(path,df, is_limited=True):\n",
    "    '''\n",
    "    Function for appending metadata to previously generated news DataFrame.\n",
    "    '''\n",
    "    if is_limited:\n",
    "        true_meta = [path+\"\\\\true-meta-information-10\\\\\"+f for f in sortDir(dir_path = path+'\\\\true-meta-information-10',is_meta=True) if isfile(join(path+'\\\\true-meta-information-10', f))]\n",
    "        fake_meta = [path+\"\\\\fake-meta-information-10\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake-meta-information-10',is_meta=True) if isfile(join(path+'\\\\fake-meta-information-10', f))]\n",
    "    else:\n",
    "        true_meta = [path+\"\\\\true-meta-information\\\\\"+f for f in sortDir(dir_path = path+'\\\\true-meta-information',is_meta=True) if isfile(join(path+'\\\\true-meta-information', f))]\n",
    "        fake_meta = [path+\"\\\\fake-meta-information\\\\\"+f for f in sortDir(dir_path = path+'\\\\fake-meta-information',is_meta=True) if isfile(join(path+'\\\\fake-meta-information', f))]\n",
    "    \n",
    "\n",
    "    #true_meta e fake_meta são listas com todas os paths para arquivos de metadata.\n",
    "    \n",
    "    columns = [\"author\", \"source\", \"category\", \"date\",\"tokens\",\"words_without_punctuation\",\"types\",\"number_of_links\",\"uppercase_words\",\"verbs\",\"subjuntive_imperative\",\"nouns\",\"adjectives\",\"adverbs\",\"modal_verbs\",\"singular_first_and_second_personal_pronouns\",\"plural_first_personal_pronouns\",\"pronouns\",\"pausality\",\"characters\",\"avg_sentence_length\",\"avg_word_length\",\"percentage_of_spelling_errors\",\"emotiveness\",\"diversity\"]\n",
    "    \n",
    "    true_metadata = pd.DataFrame(columns=columns)\n",
    "    fake_metadata = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for file in true_meta:\n",
    "        #print(file)\n",
    "        aux = pd.read_csv(file, header=None, sep = '\\n').transpose()\n",
    "        aux.columns = columns\n",
    "        true_metadata=true_metadata.append(aux)\n",
    "        \n",
    "        \n",
    "    for file in fake_meta:\n",
    "        #print(file)\n",
    "        aux = pd.read_csv(file, header=None, sep = '\\n').transpose()\n",
    "        aux.columns = columns\n",
    "        fake_metadata=fake_metadata.append(aux)\n",
    "        \n",
    "    \n",
    "    metadata = pd.DataFrame(columns=columns)\n",
    "    metadata = metadata.append(true_metadata,ignore_index=True)\n",
    "    metadata = metadata.append(fake_metadata,ignore_index=True) \n",
    "\n",
    "\n",
    "    complete_df = pd.concat([df,metadata],axis=1)\n",
    "    # Este DataFrame possui todos os textos/labels (2 colunas) e metadata (25 colunas).\n",
    "    \n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f5bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Base com 10 notícias verdadeiras e 10 notícias falsas\n",
      "1 - Base completa de notícias\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ai = int(input('''0 - Base com 10 notícias verdadeiras e 10 notícias falsas\n",
    "1 - Base completa de notícias\n",
    "'''))\n",
    "\n",
    "path = paths[ai]\n",
    "\n",
    "if ai == 0:\n",
    "    data = txtToDataframe(path) # Dataframe contendo notícias e labels.\n",
    "    complete_data = appendMetadata(path,data) # Dataframe contendo notícias, labels e metadata.\n",
    "else:\n",
    "    data = txtToDataframe(path,is_limited=False)\n",
    "    complete_data = appendMetadata(path,data,is_limited=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0bff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29daeb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>tokens</th>\n",
       "      <th>words_without_punctuation</th>\n",
       "      <th>types</th>\n",
       "      <th>number_of_links</th>\n",
       "      <th>...</th>\n",
       "      <th>singular_first_and_second_personal_pronouns</th>\n",
       "      <th>plural_first_personal_pronouns</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>pausality</th>\n",
       "      <th>characters</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>percentage_of_spelling_errors</th>\n",
       "      <th>emotiveness</th>\n",
       "      <th>diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿O Podemos decidiu  expulsar o deputado federa...</td>\n",
       "      <td>true</td>\n",
       "      <td>Naira Trindade</td>\n",
       "      <td>http://politica.estadao.com.br/blogs/coluna-do...</td>\n",
       "      <td>politica</td>\n",
       "      <td>13/12/2017</td>\n",
       "      <td>168</td>\n",
       "      <td>148</td>\n",
       "      <td>107</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.33333</td>\n",
       "      <td>761</td>\n",
       "      <td>24.6667</td>\n",
       "      <td>5.14189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.722973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Em evento realizado nesta terça-feira para div...</td>\n",
       "      <td>true</td>\n",
       "      <td>Estadão Conteúdo</td>\n",
       "      <td>http://esportes.estadao.com.br/noticias/futebo...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>26/12/2017</td>\n",
       "      <td>349</td>\n",
       "      <td>294</td>\n",
       "      <td>182</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1477</td>\n",
       "      <td>14.7</td>\n",
       "      <td>5.02381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325758</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿Após o prefeito de Manaus Arthur Virgílio (PS...</td>\n",
       "      <td>true</td>\n",
       "      <td>Juliana Diógenes</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>politica</td>\n",
       "      <td>26/12/2017</td>\n",
       "      <td>249</td>\n",
       "      <td>204</td>\n",
       "      <td>128</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1019</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4.9951</td>\n",
       "      <td>0.0147059</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿Doria vai receber Zé Celso após reunião com r...</td>\n",
       "      <td>true</td>\n",
       "      <td>Mônica Bergamo</td>\n",
       "      <td>http://www1.folha.uol.com.br/colunas/monicaber...</td>\n",
       "      <td>politica</td>\n",
       "      <td>11/1/2018</td>\n",
       "      <td>170</td>\n",
       "      <td>147</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.875</td>\n",
       "      <td>700</td>\n",
       "      <td>18.375</td>\n",
       "      <td>4.7619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0694444</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gustavo Pedreira Ferraz, que admitiu buscar ma...</td>\n",
       "      <td>true</td>\n",
       "      <td>Luiz Vassallo E Breno Pires</td>\n",
       "      <td>http://politica.estadao.com.br/blogs/fausto-ma...</td>\n",
       "      <td>politica</td>\n",
       "      <td>28/12/2017</td>\n",
       "      <td>389</td>\n",
       "      <td>341</td>\n",
       "      <td>181</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>1587</td>\n",
       "      <td>18.9444</td>\n",
       "      <td>4.65396</td>\n",
       "      <td>0.00879765</td>\n",
       "      <td>0.11039</td>\n",
       "      <td>0.530792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Muito antes da Operação Lava Jato existir, em ...</td>\n",
       "      <td>true</td>\n",
       "      <td>Liz Batista</td>\n",
       "      <td>http://acervo.estadao.com.br/noticias/acervo,p...</td>\n",
       "      <td>politica</td>\n",
       "      <td>25/11/2015</td>\n",
       "      <td>315</td>\n",
       "      <td>283</td>\n",
       "      <td>185</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2.90909</td>\n",
       "      <td>1407</td>\n",
       "      <td>25.7273</td>\n",
       "      <td>4.97173</td>\n",
       "      <td>0.0106007</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.65371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ministério Público do Maranhão (MP-MA) ingress...</td>\n",
       "      <td>true</td>\n",
       "      <td>G1 MA</td>\n",
       "      <td>https://g1.globo.com/ma/maranhao/noticia/minis...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>27/11/2017</td>\n",
       "      <td>502</td>\n",
       "      <td>459</td>\n",
       "      <td>239</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.86667</td>\n",
       "      <td>2255</td>\n",
       "      <td>30.6</td>\n",
       "      <td>4.91285</td>\n",
       "      <td>0.00653595</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.520697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cuba comemorará o primeiro aniversário da mort...</td>\n",
       "      <td>true</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://g1.globo.com/mundo/noticia/cuba-presta...</td>\n",
       "      <td>politica</td>\n",
       "      <td>24/11/2017</td>\n",
       "      <td>482</td>\n",
       "      <td>441</td>\n",
       "      <td>265</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2.41176</td>\n",
       "      <td>2132</td>\n",
       "      <td>25.9412</td>\n",
       "      <td>4.83447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.600907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s doleiros acusados de lavar dinheiro roubado ...</td>\n",
       "      <td>true</td>\n",
       "      <td>Bruno Albernaz,</td>\n",
       "      <td>https://g1.globo.com/rj/rio-de-janeiro/noticia...</td>\n",
       "      <td>politica</td>\n",
       "      <td>28/12/2017</td>\n",
       "      <td>264</td>\n",
       "      <td>234</td>\n",
       "      <td>147</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.72727</td>\n",
       "      <td>1146</td>\n",
       "      <td>21.2727</td>\n",
       "      <td>4.89744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0841122</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bolsonaro é um liberal completo, diz president...</td>\n",
       "      <td>true</td>\n",
       "      <td>Marco Rodrigo Almeida</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2018/01/194...</td>\n",
       "      <td>politica</td>\n",
       "      <td>12/1/2018</td>\n",
       "      <td>1028</td>\n",
       "      <td>865</td>\n",
       "      <td>474</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>2.85965</td>\n",
       "      <td>4205</td>\n",
       "      <td>15.1754</td>\n",
       "      <td>4.86127</td>\n",
       "      <td>0.00115607</td>\n",
       "      <td>0.271505</td>\n",
       "      <td>0.547977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kátia Abreu diz que vai colocar sua expulsão e...</td>\n",
       "      <td>fake</td>\n",
       "      <td>mrk</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/30/katia...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>211</td>\n",
       "      <td>185</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>815</td>\n",
       "      <td>14.2308</td>\n",
       "      <td>4.40541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Blog esquerdista dá a entender que reclamar de...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/28/blog-...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>356</td>\n",
       "      <td>300</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.29412</td>\n",
       "      <td>1321</td>\n",
       "      <td>17.6471</td>\n",
       "      <td>4.40333</td>\n",
       "      <td>0.0133333</td>\n",
       "      <td>0.277372</td>\n",
       "      <td>0.623333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alckmin diz que por ele PSDB desembarca, mas...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/28/alckm...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>274</td>\n",
       "      <td>224</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.57143</td>\n",
       "      <td>1075</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.79911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262136</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cara de pau não tem limites: Zé Celso aciona M...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/28/cara-...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>319</td>\n",
       "      <td>291</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>1341</td>\n",
       "      <td>24.25</td>\n",
       "      <td>4.60825</td>\n",
       "      <td>0.00343643</td>\n",
       "      <td>0.18254</td>\n",
       "      <td>0.635739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Temer resolve o problema de Luislinda: liberd...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/27/temer...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>162</td>\n",
       "      <td>133</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2.63636</td>\n",
       "      <td>654</td>\n",
       "      <td>12.0909</td>\n",
       "      <td>4.91729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.721804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Moro está certo ao não se arrepender de divulg...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/27/moro-...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>223</td>\n",
       "      <td>193</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2.14286</td>\n",
       "      <td>892</td>\n",
       "      <td>13.7857</td>\n",
       "      <td>4.62176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.668394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MP pede proibição de filmagens no MAM e acaba ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/27/mp-pe...</td>\n",
       "      <td>sociedade_cotidiano</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>224</td>\n",
       "      <td>202</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.69231</td>\n",
       "      <td>963</td>\n",
       "      <td>15.5385</td>\n",
       "      <td>4.76733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.663366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hoje completou um ano da morte de um dos psico...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/25/hoje-...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>217</td>\n",
       "      <td>184</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0625</td>\n",
       "      <td>797</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.33152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.679348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Palocci vai contar que Lula pagou propina a ex...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/25/paloc...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>110</td>\n",
       "      <td>101</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>460</td>\n",
       "      <td>20.2</td>\n",
       "      <td>4.55446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.673267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dr. Ray peita Bolsonaro, chama-o de conservad...</td>\n",
       "      <td>fake</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ceticismopolitico.com/2017/11/24/dr-ra...</td>\n",
       "      <td>politica</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>289</td>\n",
       "      <td>254</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1205</td>\n",
       "      <td>18.1429</td>\n",
       "      <td>4.74409</td>\n",
       "      <td>0.00787402</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.641732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texts labels  \\\n",
       "0   ﻿O Podemos decidiu  expulsar o deputado federa...   true   \n",
       "1   Em evento realizado nesta terça-feira para div...   true   \n",
       "2   ﻿Após o prefeito de Manaus Arthur Virgílio (PS...   true   \n",
       "3   ﻿Doria vai receber Zé Celso após reunião com r...   true   \n",
       "4   Gustavo Pedreira Ferraz, que admitiu buscar ma...   true   \n",
       "5   Muito antes da Operação Lava Jato existir, em ...   true   \n",
       "6   Ministério Público do Maranhão (MP-MA) ingress...   true   \n",
       "7   Cuba comemorará o primeiro aniversário da mort...   true   \n",
       "8   s doleiros acusados de lavar dinheiro roubado ...   true   \n",
       "9   Bolsonaro é um liberal completo, diz president...   true   \n",
       "10  Kátia Abreu diz que vai colocar sua expulsão e...   fake   \n",
       "11  Blog esquerdista dá a entender que reclamar de...   fake   \n",
       "12  Alckmin diz que por ele PSDB desembarca, mas...   fake   \n",
       "13  Cara de pau não tem limites: Zé Celso aciona M...   fake   \n",
       "14  Temer resolve o problema de Luislinda: liberd...   fake   \n",
       "15  Moro está certo ao não se arrepender de divulg...   fake   \n",
       "16  MP pede proibição de filmagens no MAM e acaba ...   fake   \n",
       "17  Hoje completou um ano da morte de um dos psico...   fake   \n",
       "18  Palocci vai contar que Lula pagou propina a ex...   fake   \n",
       "19  Dr. Ray peita Bolsonaro, chama-o de conservad...   fake   \n",
       "\n",
       "                         author  \\\n",
       "0                Naira Trindade   \n",
       "1              Estadão Conteúdo   \n",
       "2              Juliana Diógenes   \n",
       "3                Mônica Bergamo   \n",
       "4   Luiz Vassallo E Breno Pires   \n",
       "5                   Liz Batista   \n",
       "6                         G1 MA   \n",
       "7                       Reuters   \n",
       "8               Bruno Albernaz,   \n",
       "9         Marco Rodrigo Almeida   \n",
       "10                          mrk   \n",
       "11                         None   \n",
       "12                         None   \n",
       "13                         None   \n",
       "14                         None   \n",
       "15                         None   \n",
       "16                         None   \n",
       "17                         None   \n",
       "18                         None   \n",
       "19                         None   \n",
       "\n",
       "                                               source             category  \\\n",
       "0   http://politica.estadao.com.br/blogs/coluna-do...             politica   \n",
       "1   http://esportes.estadao.com.br/noticias/futebo...  sociedade_cotidiano   \n",
       "2   http://politica.estadao.com.br/noticias/geral,...             politica   \n",
       "3   http://www1.folha.uol.com.br/colunas/monicaber...             politica   \n",
       "4   http://politica.estadao.com.br/blogs/fausto-ma...             politica   \n",
       "5   http://acervo.estadao.com.br/noticias/acervo,p...             politica   \n",
       "6   https://g1.globo.com/ma/maranhao/noticia/minis...  sociedade_cotidiano   \n",
       "7   https://g1.globo.com/mundo/noticia/cuba-presta...             politica   \n",
       "8   https://g1.globo.com/rj/rio-de-janeiro/noticia...             politica   \n",
       "9   http://www1.folha.uol.com.br/poder/2018/01/194...             politica   \n",
       "10  https://ceticismopolitico.com/2017/11/30/katia...             politica   \n",
       "11  https://ceticismopolitico.com/2017/11/28/blog-...  sociedade_cotidiano   \n",
       "12  https://ceticismopolitico.com/2017/11/28/alckm...             politica   \n",
       "13  https://ceticismopolitico.com/2017/11/28/cara-...             politica   \n",
       "14  https://ceticismopolitico.com/2017/11/27/temer...             politica   \n",
       "15  https://ceticismopolitico.com/2017/11/27/moro-...             politica   \n",
       "16  https://ceticismopolitico.com/2017/11/27/mp-pe...  sociedade_cotidiano   \n",
       "17  https://ceticismopolitico.com/2017/11/25/hoje-...             politica   \n",
       "18  https://ceticismopolitico.com/2017/11/25/paloc...             politica   \n",
       "19  https://ceticismopolitico.com/2017/11/24/dr-ra...             politica   \n",
       "\n",
       "          date tokens words_without_punctuation types number_of_links  ...  \\\n",
       "0   13/12/2017    168                       148   107            None  ...   \n",
       "1   26/12/2017    349                       294   182            None  ...   \n",
       "2   26/12/2017    249                       204   128            None  ...   \n",
       "3    11/1/2018    170                       147   102            None  ...   \n",
       "4   28/12/2017    389                       341   181            None  ...   \n",
       "5   25/11/2015    315                       283   185            None  ...   \n",
       "6   27/11/2017    502                       459   239            None  ...   \n",
       "7   24/11/2017    482                       441   265            None  ...   \n",
       "8   28/12/2017    264                       234   147            None  ...   \n",
       "9    12/1/2018   1028                       865   474            None  ...   \n",
       "10  2017-11-30    211                       185   120               0  ...   \n",
       "11  2017-11-28    356                       300   187               0  ...   \n",
       "12  2017-11-28    274                       224   150               0  ...   \n",
       "13  2017-11-28    319                       291   185               0  ...   \n",
       "14  2017-11-27    162                       133    96               0  ...   \n",
       "15  2017-11-27    223                       193   129               0  ...   \n",
       "16  2017-11-27    224                       202   134               0  ...   \n",
       "17  2017-11-25    217                       184   125               0  ...   \n",
       "18  2017-11-25    110                       101    68               0  ...   \n",
       "19  2017-11-24    289                       254   163               0  ...   \n",
       "\n",
       "   singular_first_and_second_personal_pronouns plural_first_personal_pronouns  \\\n",
       "0                                            0                              0   \n",
       "1                                            0                              0   \n",
       "2                                            3                              0   \n",
       "3                                            0                              0   \n",
       "4                                            0                              0   \n",
       "5                                            0                              0   \n",
       "6                                            0                              0   \n",
       "7                                            0                              0   \n",
       "8                                            0                              0   \n",
       "9                                            3                              1   \n",
       "10                                           2                              0   \n",
       "11                                           0                              0   \n",
       "12                                           1                              0   \n",
       "13                                           0                              0   \n",
       "14                                           0                              0   \n",
       "15                                           3                              0   \n",
       "16                                           0                              0   \n",
       "17                                           0                              0   \n",
       "18                                           0                              0   \n",
       "19                                           1                              0   \n",
       "\n",
       "   pronouns pausality characters avg_sentence_length avg_word_length  \\\n",
       "0         7   3.33333        761             24.6667         5.14189   \n",
       "1        29      2.75       1477                14.7         5.02381   \n",
       "2         8       3.0       1019                13.6          4.9951   \n",
       "3         7     2.875        700              18.375          4.7619   \n",
       "4        14   2.66667       1587             18.9444         4.65396   \n",
       "5        11   2.90909       1407             25.7273         4.97173   \n",
       "6         9   2.86667       2255                30.6         4.91285   \n",
       "7        33   2.41176       2132             25.9412         4.83447   \n",
       "8         5   2.72727       1146             21.2727         4.89744   \n",
       "9        63   2.85965       4205             15.1754         4.86127   \n",
       "10       26       2.0        815             14.2308         4.40541   \n",
       "11       30   3.29412       1321             17.6471         4.40333   \n",
       "12       14   3.57143       1075                16.0         4.79911   \n",
       "13       23   2.33333       1341               24.25         4.60825   \n",
       "14       12   2.63636        654             12.0909         4.91729   \n",
       "15       23   2.14286        892             13.7857         4.62176   \n",
       "16       14   1.69231        963             15.5385         4.76733   \n",
       "17       10    2.0625        797                11.5         4.33152   \n",
       "18        2       1.8        460                20.2         4.55446   \n",
       "19       20       2.5       1205             18.1429         4.74409   \n",
       "\n",
       "   percentage_of_spelling_errors emotiveness diversity  \n",
       "0                            0.0    0.134328  0.722973  \n",
       "1                            0.0    0.325758  0.619048  \n",
       "2                      0.0147059        0.16  0.627451  \n",
       "3                            0.0   0.0694444  0.693878  \n",
       "4                     0.00879765     0.11039  0.530792  \n",
       "5                      0.0106007    0.174242   0.65371  \n",
       "6                     0.00653595    0.122449  0.520697  \n",
       "7                            0.0    0.237569  0.600907  \n",
       "8                            0.0   0.0841122  0.628205  \n",
       "9                     0.00115607    0.271505  0.547977  \n",
       "10                           0.0    0.263158  0.648649  \n",
       "11                     0.0133333    0.277372  0.623333  \n",
       "12                           0.0    0.262136  0.669643  \n",
       "13                    0.00343643     0.18254  0.635739  \n",
       "14                           0.0    0.303571  0.721804  \n",
       "15                           0.0    0.253012  0.668394  \n",
       "16                           0.0    0.129032  0.663366  \n",
       "17                           0.0    0.457143  0.679348  \n",
       "18                           0.0    0.145833  0.673267  \n",
       "19                    0.00787402    0.241667  0.641732  \n",
       "\n",
       "[20 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c597e091",
   "metadata": {},
   "source": [
    "## Analisando Base de notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7070d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando tamanho de notícias (plotar histograma contendo as quantidades de notícias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259eaf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificando assuntos\n",
    "\n",
    "ax = complete_data['category'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(5,3),\n",
    "                                    title=\"Quantidade de notícias total por categoria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8c571",
   "metadata": {},
   "source": [
    "## Extraindo features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5718d62",
   "metadata": {},
   "source": [
    "##### Bag-of-words\n",
    "O Bag-of-words realiza uma contagem da quantidade de palavras existentes em um conjunto grande de textos. Para utilizar o efeito de considerar palavras com o mesmo significado, devemos pré-processar os textos e lematizar cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b597d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o pacote de língua portuguesa para o processador Spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d839fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4807c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defininido funções de preprocessamento\n",
    "\n",
    "def removePunct(text):\n",
    "    '''\n",
    "    Removes any punctuation included in string.punctuation.\n",
    "    '''\n",
    "    translator = text.maketrans({key:'' for key in string.punctuation}) # Translates any punctuation into ''\n",
    "    return text.translate(translator)\n",
    "\n",
    "def removeNumbers(text):\n",
    "    '''\n",
    "    Removes any number character in text.\n",
    "    '''\n",
    "    return re.sub('[0-9]', '' , text) # Translates any number into ''\n",
    "\n",
    "def removeStopWords(string):\n",
    "    '''\n",
    "    Removes any portuguese stopwords, using Spacy's standard package.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    Lemmatizes text word-by-word. Notice that lemmatizing is not as harsh as stemming, which makes the final text easier to read and understand in common language.\n",
    "    '''\n",
    "    doc = nlp(string)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "def prep(string, useStopWords = True, lemma = True):\n",
    "    '''\n",
    "    Executes previously defined preprocessing in text.\n",
    "    '''\n",
    "\n",
    "    result = removeNumbers(removePunct(string)).lower()\n",
    "    \n",
    "    if useStopWords and lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc if token.is_stop is False])\n",
    "    elif useStopWords:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.text for token in doc if token.is_stop is False])\n",
    "    elif lemma:\n",
    "        doc = nlp(result)\n",
    "        result = ' '.join([token.lemma_ for token in doc])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bfd933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlos viemos pra zonear \n",
      " esporte bosta negócio cachaça ganhe apanhar ir brindar \n",
      " pinga querer limãaaaaao mulher tesãaaaaao dia eesc amar precisar macacada puta merdo cagar \n",
      " legal calcular integral grafite calcular limite\n"
     ]
    }
   ],
   "source": [
    "text = '''Nós somos lá de São Carlos, viemos aqui pra zonear.\n",
    "No esporte, nós somos bosta, nosso negócio é a cachaça. E mesmo, que nós não ganhe, que nós apanhe, vamos brindar.\n",
    "A pinga, queremos com limãaaaaao. Mulheres, com muito mais tesãaaaaao. Se um dia a EESC amada precisar da macacada, puta merda, que cagada, 1,2,3,4.\n",
    "Como é legal, calcular a integral. Mesmo sem grafite, calculamos o limite.'''\n",
    "\n",
    "print(prep(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8843e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petrobra anunciar segundafeira   elevar preço diesel distribuidora preço médio litro passar r   r   terça   aumento \n",
      "\n",
      " preço gasolina gás cozinha ser alterar \n",
      "\n",
      " petroleira diesel sofrer reajuste há   dia –   março petrobra alta refletir elevação observar preço mercado\n"
     ]
    }
   ],
   "source": [
    "text_news = '''A Petrobras anunciou nesta segunda-feira (9) que vai elevar o preço do diesel para as distribuidoras. O preço médio do litro vai passar de R$ 4,51 para R$ 4,91 a partir de terça (10), um aumento de 8,87%.\n",
    "\n",
    "Os preços da gasolina e do gás de cozinha não serão alterados.\n",
    "\n",
    "Segundo a petroleira, o diesel não sofria reajuste há 60 dias – desde 11 de março. Naquele momento, diz a Petrobras, a alta refletia \"apenas parte da elevação observada nos preços de mercado\".'''\n",
    "\n",
    "print(prep(text_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81296d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeMinFreq(data, features, min_freq = 1):\n",
    "    # Realiza a soma da frequência de cada palavra da matriz vetorizada\n",
    "    cols_sum = np.sum(data, axis=0)\n",
    "\n",
    "    del_indexes = []\n",
    "    # Analisa cada valor das contagens de frequência do cols_sum, assignando um índice i, e salva o índice em del_indexes[]\n",
    "    # quando a contagem for acima da min_freq\n",
    "    for i, val in zip(range(len(cols_sum)), cols_sum):\n",
    "        if val < min_freq:\n",
    "            del_indexes.append(i)\n",
    "            \n",
    "    data = np.delete(data,del_indexes,1) # Deleta coluna\n",
    "    features = np.delete(features,del_indexes,0) # Deleta linha\n",
    "    return (data, features)\n",
    "\n",
    "\n",
    "def normalizeData(data):\n",
    "    rows_sum = np.sum(data, axis=1)\n",
    "    data = (data.T / rows_sum).T\n",
    "    return data\n",
    "\n",
    "\n",
    "def loadCount(texts, min_freq = 1, binary = False, normalize = True):\n",
    "\n",
    "    # Instanciando o CountVectorizer\n",
    "    vectorizer = CountVectorizer(input = 'content', preprocessor = prep, encoding='utf-8', binary = binary);\n",
    "    \n",
    "    # Aplicando processo de vetorização\n",
    "    data = np.array(vectorizer.fit_transform(text_list).todense());\n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    # Se min_freq for 1, então todos os tokens são considerados\n",
    "    if(min_freq > 1):\n",
    "        data, features = removeMinFreq(data, features, min_freq)\n",
    "    if(normalize):\n",
    "        data = normalizeData(data)\n",
    "\n",
    "    return pd.DataFrame(data,columns = features)\n",
    "\n",
    "def loadTfidf(texts):\n",
    "\n",
    "    # Instanciando o Tf-Idf como vetorizador\n",
    "    vectorizer = TfidfVectorizer(input = 'content', preprocessor = prep, encoding='utf-8')\n",
    "    \n",
    "    data = np.array(vectorizer.fit_transform(texts).todense());\n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    return pd.DataFrame(data,columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "463404f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando as funções definidas previamente, criamos dataframes para o bag-of-words (frequência geral e TF-IDF).\n",
    "\n",
    "text_list = complete_data['texts'].to_list()\n",
    "\n",
    "df_bow = loadCount(text_list, normalize = False)\n",
    "df_tfidf = loadTfidf(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eb38550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fe997d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paulo</th>\n",
       "      <th>ano</th>\n",
       "      <th>bolsonaro</th>\n",
       "      <th>dia</th>\n",
       "      <th>dizer</th>\n",
       "      <th>fazer</th>\n",
       "      <th>federal</th>\n",
       "      <th>governo</th>\n",
       "      <th>partido</th>\n",
       "      <th>presidente</th>\n",
       "      <th>público</th>\n",
       "      <th>receber</th>\n",
       "      <th>ser</th>\n",
       "      <th>ter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paulo  ano  bolsonaro  dia  dizer  fazer  federal  governo  partido  \\\n",
       "0       0    0          0    0      0      0        2        0        3   \n",
       "1       0    2          0    0      1      1        0        0        0   \n",
       "2       2    1          0    1      3      0        0        0        3   \n",
       "3       0    0          0    2      0      0        0        0        0   \n",
       "4       3    1          0    0      0      1        0        2        0   \n",
       "5       0    1          0    0      2      0        2        1        0   \n",
       "6       0    2          0    4      0      1        0        0        0   \n",
       "7       0    5          0    2      1      0        0        3        1   \n",
       "8       0    0          0    0      0      1        3        1        0   \n",
       "9       2    4          9    2      2      2        4        1        7   \n",
       "10      0    0          0    0      2      0        0        0        1   \n",
       "11      0    0          0    0      1      0        0        0        0   \n",
       "12      1    0          0    0      0      0        0        3        2   \n",
       "13      0    1          0    0      0      3        3        0        0   \n",
       "14      0    0          0    1      0      0        1        0        0   \n",
       "15      0    1          0    1      2      0        1        1        0   \n",
       "16      2    0          0    0      0      0        0        0        0   \n",
       "17      0    3          0    1      0      1        0        0        0   \n",
       "18      0    0          0    0      0      0        0        0        0   \n",
       "19      0    0          5    0      2      1        0        0        0   \n",
       "\n",
       "    presidente  público  receber  ser  ter  \n",
       "0            0        0        1    1    1  \n",
       "1            0        0        0    1    0  \n",
       "2            2        0        0    0    0  \n",
       "3            0        0        3    0    0  \n",
       "4            1        0        0    2    1  \n",
       "5            1        2        0    1    0  \n",
       "6            0        4        1    2    0  \n",
       "7            2        3        1    1    0  \n",
       "8            0        2        0    0    0  \n",
       "9            4        0        2    0    2  \n",
       "10           0        0        0    1    0  \n",
       "11           0        0        1    0    2  \n",
       "12           1        0        0    1    2  \n",
       "13           0        3        0    0    0  \n",
       "14           1        0        0    0    0  \n",
       "15           0        0        0    1    1  \n",
       "16           0        1        0    2    0  \n",
       "17           0        1        1    2    1  \n",
       "18           0        0        0    1    0  \n",
       "19           0        0        0    1    0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e0b65",
   "metadata": {},
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a2f1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulos para modelagem de aprendizado de máquina tradicionais\n",
    "\n",
    "# Viabilizadores\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Algoritmos\n",
    "from sklearn.svm import SVC #, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature selection & relatório de resultados\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import classification_report , confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "611ecfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignVariables(df_features, df_complete_data):\n",
    "    X = df_features.values\n",
    "    y = df_complete_data['labels']\n",
    "    \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9330f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignando variáveis dependentes e independentes e dividindo dados em conjunto de teste e treino\n",
    "\n",
    "X,y = assignVariables(df_bow,complete_data)\n",
    "\n",
    "test_size = 0.20\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b0b0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1368)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ccde8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1368)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb035a1d",
   "metadata": {},
   "source": [
    "### Selecione um algoritmo:\n",
    "0 - Logistic Regression  \n",
    "1 - Naive Bayes  \n",
    "2 - Gradient Boosting  \n",
    "3 - Random Forests  \n",
    "4 - Support Vector Machine (SVM)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4db26ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d88bf66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insira o ID do algoritmo a ser usado para treinamento do modelo: 0\n",
      "Salvar modelo?\n",
      "0 - Não\n",
      "1 - Sim\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Texto       0.67      1.00      0.80        10\n",
      "       Label       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.83      0.75      0.73        20\n",
      "weighted avg       0.83      0.75      0.73        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = [LogisticRegression(), MultinomialNB(), GradientBoostingClassifier(), RandomForestClassifier(), SVC()]\n",
    "\n",
    "choice = input(\"Insira o ID do algoritmo a ser usado para treinamento do modelo: \")\n",
    "save_model = int(input('''Salvar modelo?\n",
    "0 - Não\n",
    "1 - Sim\n",
    "'''))\n",
    "\n",
    "classifier = classifier[int(choice)]\n",
    "\n",
    "feature_selection = 100\n",
    "\n",
    "X_best = SelectKBest(mutual_info_classif,k=feature_selection).fit_transform(X,y)\n",
    "\n",
    "predictions = (cross_val_predict(classifier, X_best, y, cv=5))\n",
    "\n",
    "dataset_name = str(X.shape[0])+'_news'\n",
    "if save_model==1:\n",
    "    model_name = (classifier.__class__.__name__ + '_' + (dataset_name + '.pkl').lower())\n",
    "    classifier.fit(X_best, y)\n",
    "    joblib.dump(classifier,model_name)\n",
    "\n",
    "target_name = ['Texto','Label']\n",
    "print(classification_report(y, predictions, target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42aeb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
